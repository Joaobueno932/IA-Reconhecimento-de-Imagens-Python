{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30034,"status":"ok","timestamp":1684730228824,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"},"user_tz":180},"id":"CaFuQMoh67K4","outputId":"5c4f4791-bc08-49b5-9275-b168e443204e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"oeiIlQiYMR6e"},"source":["Passa arquivos de uma pasta do drive pra outra, usada pra passar as imagens de um banco de dados pra outra pasta"]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"qIVyhaHgFxBI","executionInfo":{"status":"ok","timestamp":1684597796552,"user_tz":180,"elapsed":13983,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"}},"outputId":"7537117e-2aac-4290-aeb9-3882aa9f6138"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-b28705ef-493b-48a2-9a0e-f8b0a607d766\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b28705ef-493b-48a2-9a0e-f8b0a607d766\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving OrigaList.csv to OrigaList.csv\n"]}]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","\n","directory = \"/content/drive/MyDrive/compara_segmentadores/data2/A/DRIVEpng/tudo/anotacoes/\"\n","\n","for filename in os.listdir(directory):\n","    if filename.endswith(\".jpg\"):\n","        filepath = os.path.join(directory, filename)\n","        new_filepath = os.path.join(directory, os.path.splitext(filename)[0] + \".png\")\n","\n","        img = Image.open(filepath)\n","        img = img.convert(\"RGB\")\n","        img.save(new_filepath, \"PNG\")\n","\n","        os.remove(filepath)\n","\n","print(\"Conversion completed.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1fHeM-RwJz-c","executionInfo":{"status":"ok","timestamp":1684730463493,"user_tz":180,"elapsed":147745,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"}},"outputId":"88fb570c-d607-407f-e003-492266320549"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Conversion completed.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nMdIaa5f_Yl","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"error","timestamp":1684598189497,"user_tz":180,"elapsed":576,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"}},"outputId":"091552d2-7d2f-48c9-e06b-50ee41889adc"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/Masks/001.jpg\n"]},{"output_type":"error","ename":"Error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-91b238358e4a>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/Masks/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgg\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\"/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/classe 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Destination path '%s' already exists\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mError\u001b[0m: Destination path '/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/classe 0/001.jpg' already exists"]}],"source":["import csv\n","import shutil, sys                                                                                                                                                    \n","\n","out=open(\"OrigaList.csv\",\"r\")\n","data=csv.reader(out)\n","#data=[row for row in data]\n","data=[[row[0], (row[1]), (row[2]), (row[3]),(row[4])] for row in data] \n","c=0\n","class1 = []\n","for row in data:\n","      #print(row)\n","      if row[4] == '1':\n","        #print(\"oh NOOOO\")\n","        aa = row[1]\n","        class1.append(aa)\n","        #print(class1)\n","        ee = \"/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/Masks/\"+aa\n","        print(ee)\n","        shutil.move( ee, \"/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/classe 1\")\n","      elif row[4] == '0':\n","        #print(\"oh Siiiii\")\n","        bb = row[1]\n","        class1.append(bb)\n","        #print(class1)\n","       \n","        gg = \"/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/Masks/\"+bb\n","        print(gg)\n","        shutil.move(gg ,\"/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/classe 0\") \n","\n","   \n","out.close()\n","print (data)\n","new_data=[[row[0], (row[1]), (row[2]), (row[3]),(row[4])]  for row in data]\n","#print (new_data)\n","out=open(\"new_data.csv\",\"w\")\n","output=csv.writer(out)\n","for row in new_data:\n","    output.writerow(row)\n","out.close()"]},{"cell_type":"code","source":["import os \n","print(os.listdir((\"/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/Masks\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrqVU2k_I6nH","executionInfo":{"status":"ok","timestamp":1684598220055,"user_tz":180,"elapsed":5,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"}},"outputId":"e52a5909-5947-455c-a22c-240c93f86a1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0VLEQorP7RGY"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","import keras.utils as image\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZaVhrrKp8dbf"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","import keras.utils as image\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","\n","#import os\n","#for dirname, _, filenames in os.walk('/kaggle/input/glaucoma-datasets'):\n","#    for filename in filenames:\n","#        print(os.path.join(dirname, filename))\n","        \n","\n","\n","\n","# Initialising the CNN\n","classifier = Sequential()\n","# Step 1 - Convolution\n","classifier.add(Conv2D(32, (3, 3), input_shape = (256,256, 3), activation = 'relu'))\n","# Step 2 - Pooling\n","classifier.add(MaxPooling2D(pool_size = (2, 2)))\n","# Adding a second convolutional layer\n","classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n","classifier.add(MaxPooling2D(pool_size = (2, 2)))\n","# Step 3 - Flattening\n","classifier.add(Flatten())\n","# Step 4 - Full connection\n","classifier.add(Dense(units = 128, activation = 'relu'))\n","classifier.add(Dense(units = 1, activation = 'sigmoid'))\n","# Compiling the CNN\n","classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAV2OjNIm3--"},"outputs":[],"source":["# Callbacks\n","checkpoint = ModelCheckpoint(\"f1.h5\", monitor='accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n","reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, verbose=0, mode='auto', cooldown=0, min_lr=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"voW9DLIJ8d8Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684193912132,"user_tz":180,"elapsed":1288090,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"}},"outputId":"3f235010-5421-46d5-a94f-cd0838e03515"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 587 images belonging to 2 classes.\n","Found 40 images belonging to 2 classes.\n","Found 23 images belonging to 2 classes.\n","Epoch 1/10\n","19/19 [==============================] - ETA: 0s - loss: 1.1080 - accuracy: 0.6848\n","Epoch 1: accuracy did not improve from 0.75615\n","19/19 [==============================] - 129s 7s/step - loss: 1.1080 - accuracy: 0.6848 - val_loss: 0.7493 - val_accuracy: 0.4783 - lr: 0.0010\n","Epoch 2/10\n","19/19 [==============================] - ETA: 0s - loss: 0.5581 - accuracy: 0.7615\n","Epoch 2: accuracy improved from 0.75615 to 0.76150, saving model to f1.h5\n","19/19 [==============================] - 122s 6s/step - loss: 0.5581 - accuracy: 0.7615 - val_loss: 0.9879 - val_accuracy: 0.4783 - lr: 0.0010\n","Epoch 3/10\n","19/19 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7615\n","Epoch 3: accuracy did not improve from 0.76150\n","19/19 [==============================] - 122s 6s/step - loss: 0.5662 - accuracy: 0.7615 - val_loss: 1.0959 - val_accuracy: 0.4783 - lr: 0.0010\n","Epoch 4/10\n","19/19 [==============================] - ETA: 0s - loss: 0.5604 - accuracy: 0.7615\n","Epoch 4: accuracy did not improve from 0.76150\n","19/19 [==============================] - 131s 7s/step - loss: 0.5604 - accuracy: 0.7615 - val_loss: 1.0198 - val_accuracy: 0.4783 - lr: 0.0010\n","Epoch 5/10\n","19/19 [==============================] - ETA: 0s - loss: 0.5441 - accuracy: 0.7615\n","Epoch 5: accuracy did not improve from 0.76150\n","19/19 [==============================] - 123s 6s/step - loss: 0.5441 - accuracy: 0.7615 - val_loss: 0.9295 - val_accuracy: 0.4783 - lr: 1.0000e-04\n","Epoch 6/10\n","19/19 [==============================] - ETA: 0s - loss: 0.5436 - accuracy: 0.7615\n","Epoch 6: accuracy did not improve from 0.76150\n","19/19 [==============================] - 118s 6s/step - loss: 0.5436 - accuracy: 0.7615 - val_loss: 0.9110 - val_accuracy: 0.4783 - lr: 1.0000e-04\n","Epoch 7/10\n","19/19 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.7615\n","Epoch 7: accuracy did not improve from 0.76150\n","19/19 [==============================] - 119s 6s/step - loss: 0.5414 - accuracy: 0.7615 - val_loss: 0.9287 - val_accuracy: 0.4783 - lr: 1.0000e-04\n","Epoch 8/10\n","19/19 [==============================] - ETA: 0s - loss: 0.5464 - accuracy: 0.7615\n","Epoch 8: accuracy did not improve from 0.76150\n","19/19 [==============================] - 119s 6s/step - loss: 0.5464 - accuracy: 0.7615 - val_loss: 0.8934 - val_accuracy: 0.4783 - lr: 1.0000e-04\n","Epoch 9/10\n","19/19 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.7615\n","Epoch 9: accuracy did not improve from 0.76150\n","19/19 [==============================] - 127s 7s/step - loss: 0.5435 - accuracy: 0.7615 - val_loss: 0.9312 - val_accuracy: 0.4783 - lr: 1.0000e-04\n","Epoch 10/10\n","19/19 [==============================] - ETA: 0s - loss: 0.5407 - accuracy: 0.7615\n","Epoch 10: accuracy did not improve from 0.76150\n","19/19 [==============================] - 116s 6s/step - loss: 0.5407 - accuracy: 0.7615 - val_loss: 0.9355 - val_accuracy: 0.4783 - lr: 1.0000e-05\n"]}],"source":["from keras.preprocessing.image import ImageDataGenerator\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","shear_range = 0.2,\n","zoom_range = 0.2,\n","horizontal_flip = True)\n","# print(train_datagen)\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","training_set = train_datagen.flow_from_directory('/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/train/',\n","target_size = (256,256),\n","batch_size = 32,\n","class_mode = 'binary')\n","# print(test_datagen)\n","test_set = test_datagen.flow_from_directory('/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/test/',\n","target_size = (256,256),\n","batch_size = 32,\n","class_mode = 'binary')\n","\n","val_datagen = ImageDataGenerator(rescale = 1./255)\n","val_set = val_datagen.flow_from_directory('/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/valid/',\n","target_size = (256, 256),\n","batch_size = 32,\n","class_mode = 'binary')\n","\n","history = classifier.fit(training_set,  \n","                         epochs = 10,\n","                         validation_data = val_set,\n","                         callbacks=[checkpoint, reduce_lr])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IP7DIt16OVK0"},"outputs":[],"source":["\n","!apt-get install python3.6\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RlFPRjdGPpvF"},"outputs":[],"source":["!pip install tensorflow==2.8.0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VNolHVt-0ylg"},"outputs":[],"source":["!pip install --upgrade tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":693},"id":"lJBdXFOXxv8j","outputId":"9c130cee-2ccd-4708-cdeb-9bfd2caa421b","executionInfo":{"status":"error","timestamp":1684191920241,"user_tz":180,"elapsed":128852,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 470 images belonging to 2 classes.\n","Found 4 images belonging to 2 classes.\n","Found 587 images belonging to 2 classes.\n","Found 23 images belonging to 2 classes.\n","Epoch 1/100\n","45/45 [==============================] - ETA: 0s - loss: 32919.1250 - accuracy: 0.7133\n","Epoch 1: accuracy improved from -inf to 0.71333, saving model to f1.h5\n","45/45 [==============================] - 140s 3s/step - loss: 32919.1250 - accuracy: 0.7133 - val_loss: 0.9355 - val_accuracy: 0.4783 - lr: 0.1000\n","Epoch 2/100\n","45/45 [==============================] - ETA: 0s - loss: 0.5912 - accuracy: 0.7422\n","Epoch 2: accuracy improved from 0.71333 to 0.74222, saving model to f1.h5\n","45/45 [==============================] - 108s 2s/step - loss: 0.5912 - accuracy: 0.7422 - val_loss: 0.8860 - val_accuracy: 0.4783 - lr: 0.1000\n","Epoch 3/100\n","45/45 [==============================] - ETA: 0s - loss: 0.5718 - accuracy: 0.7562\n","Epoch 3: accuracy improved from 0.74222 to 0.75615, saving model to f1.h5\n","45/45 [==============================] - 103s 2s/step - loss: 0.5718 - accuracy: 0.7562 - val_loss: 0.8629 - val_accuracy: 0.4783 - lr: 0.1000\n","Epoch 4/100\n","22/45 [=============>................] - ETA: 52s - loss: 0.5949 - accuracy: 0.7227"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-bcc1ce43df40>\u001b[0m in \u001b[0;36m<cell line: 105>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# Treinar o modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m model_info = model.fit(\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","\n","# Definir o tamanho das imagens de entrada\n","img_size = (224, 224)\n","\n","# Definir o tamanho do batch e número de épocas\n","batch_size = 10\n","epochs = 100\n","\n","# Definir o número de passos por época para o conjunto de treinamento e validação\n","train_steps_per_epoch = 455 // batch_size\n","val_steps_per_epoch = 30 // batch_size\n","\n","# Definir o número de filtros para cada camada convolucional\n","num_filters = [32, 64, 128]\n","\n","# Definir a taxa de aprendizagem inicial\n","learning_rate = 0.1\n","\n","# Criar geradores de imagens para treinamento e validação\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,      # normalizar os valores dos pixels\n","    rotation_range=20,   # girar aleatoriamente as imagens em até 20 graus\n","    width_shift_range=0.2,   # mover aleatoriamente as imagens horizontalmente\n","    height_shift_range=0.2,  # mover aleatoriamente as imagens verticalmente\n","    shear_range=0.2,     # aplicar cisalhamento nas imagens\n","    zoom_range=0.2,      # aplicar zoom nas imagens\n","    horizontal_flip=True,    # espelhar aleatoriamente as imagens horizontalmente\n","    validation_split=0.2   # definir a proporção de imagens para validação\n",")\n","\n","# Criar gerador de imagens de treinamento\n","train_generator = train_datagen.flow_from_directory(\n","    '/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/train/',  # diretório com as imagens\n","    target_size=img_size,    # tamanho das imagens\n","    batch_size=batch_size,     # tamanho do lote\n","    class_mode='binary',       # modo de classificação (binário ou multiclasse)\n","    subset='training',         # usar apenas as imagens de treinamento\n","    shuffle=True               # embaralhar as imagens a cada época\n",")\n","\n","# Criar gerador de imagens de validação\n","val_generator = train_datagen.flow_from_directory(\n","    '/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/valid/',  # diretório com as imagens\n","    target_size=img_size,    # tamanho das imagens\n","    batch_size=batch_size,     # tamanho do lote\n","    class_mode='binary',       # modo de classificação (binário ou multiclasse)\n","    subset='validation',       # usar apenas as imagens de validação\n","    shuffle=True               # embaralhar as imagens a cada época\n",")\n","\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Carregar os conjuntos de treinamento e validação\n","train_set = train_datagen.flow_from_directory(\n","    directory='/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/train/',\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    class_mode='binary'\n",")\n","\n","\n","\n","val_set = val_datagen.flow_from_directory(\n","    directory='/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/valid/',\n","    target_size=img_size,\n","    batch_size=batch_size,\n","    class_mode='binary'\n",")\n","\n","# Definir o modelo da rede neural\n","model = tf.keras.models.Sequential([\n","    # Camada convolucional 1\n","    tf.keras.layers.Conv2D(num_filters[0], 3, activation='relu', input_shape=(img_size[0], img_size[1], 3)),\n","    tf.keras.layers.MaxPooling2D(2),\n","    # Camada convolucional 2\n","    tf.keras.layers.Conv2D(num_filters[1], 3, activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2),\n","    # Camada convolucional 3\n","    tf.keras.layers.Conv2D(num_filters[2], 3, activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2),\n","    # Camada Flatten\n","    tf.keras.layers.Flatten(),\n","    # Camada Dense\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    # Camada de saída\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","# Compilar o modelo\n","model.compile(\n","    loss='binary_crossentropy',\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","    metrics=['accuracy']\n",")\n","\n","# Definir os callbacks\n","#checkpoint = ModelCheckpoint('path/to/model.h5',monitor = 'val_loss', save_weights_only = False, save_best_only=True, mode='max', verbose=1,save_freq=1)\n","#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, mode='min', verbose=1)\n","\n","# Treinar o modelo\n","model_info = model.fit(\n","    train_set,\n","    epochs=epochs,\n","    validation_data=val_set,\n","    steps_per_epoch=train_steps_per_epoch,\n","    validation_steps=val_steps_per_epoch,\n","    callbacks=[checkpoint, reduce_lr]\n",")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39572,"status":"ok","timestamp":1684191962875,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"},"user_tz":180},"id":"yAAzIVzv8lhI","outputId":"283b4895-a748-4187-dc70-ad60859404cb"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-8-630d70316d5e>:6: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n","  score = classifier.evaluate_generator(test_set, steps=steps_per_epoch)\n"]},{"output_type":"stream","name":"stdout","text":["Number of samples:  40\n","Loss:  0.7236219644546509\n","Accuracy:  0.4000000059604645\n"]}],"source":["# Performance evaluation\n","#########################\n","batch_size = 32\n","num_samples = len(test_set.filenames)\n","steps_per_epoch = int(num_samples / batch_size) + 1\n","score = classifier.evaluate_generator(test_set, steps=steps_per_epoch)\n","print(\"Number of samples: \", num_samples)\n","print(\"Loss: \", score[0])\n","print(\"Accuracy: \", score[1])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"usP4LFeo8oxH"},"outputs":[],"source":["classifier.save('/content/drive/My Drive/Colab_Project/glaucoma/model.h5')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ZXvRbtd8qzI"},"outputs":[],"source":["import os\n","from keras.models import load_model\n","from PIL import Image\n","from keras.preprocessing import image\n","import numpy as np\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1289,"status":"ok","timestamp":1684191983337,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"},"user_tz":180},"id":"sSy51egP8tZg","outputId":"44dc21bc-6e5b-491e-c1f7-b03667cb3672"},"outputs":[{"output_type":"stream","name":"stdout","text":["model loaded\n"]}],"source":["target_size = (256,256)\n","model=load_model('/content/drive/My Drive/Colab_Project/glaucoma/model.h5')\n","print(\"model loaded\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":685,"status":"ok","timestamp":1684192090255,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"},"user_tz":180},"id":"nJBTY_oq8vVw","outputId":"cf120895-54d8-48e1-add7-7d0297b2d8b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 162ms/step\n","[[1.]]\n","Glaucoma\n"]}],"source":["import numpy as np\n","from keras.preprocessing import image\n","test_image = tf.keras.utils.load_img('/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/test/classe 0/007.jpg', target_size = (256,256))\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = model.predict(test_image)\n","training_set.class_indices\n","print(result)\n","if result[0][0] == 1:\n"," print(\"Glaucoma\")\n","else:\n"," print(\"Not Glaucoma\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1684192137564,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"},"user_tz":180},"id":"8080Q07O8xew","outputId":"db7fa9c3-9efb-4564-ad79-675f5013e0e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 46ms/step\n","[[1.]]\n","Glaucoma\n"]}],"source":["import numpy as np\n","from keras.preprocessing import image\n","test_image = tf.keras.utils.load_img('/content/drive/My Drive/compara_segmentadores/data2/A/ORIGA/test/classe 1/050.jpg', target_size = (256,256))\n","test_image = tf.keras.utils.img_to_array(test_image)\n","\n","test_image = np.expand_dims(test_image, axis = 0)\n","#print(test_image)\n","result = model.predict(test_image)\n","print(result)\n","training_set.class_indices\n","if result[0][0] == 1:\n"," print(\"Glaucoma\")\n","else:\n"," print(\"Not Glaucoma\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWUKO7D58zyf"},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt\n","from PIL import  Image\n","%matplotlib inline\n","plt.style.use('fivethirtyeight')\n","def plot_model_history(model_history):\n","    fig, axs = plt.subplots(1,2,figsize=(15,5))\n","    # summarize history for accuracy\n","    axs[0].plot(range(1,len(model_history.history['binary_accuracy'])+1),model_history.history['acc'],metrics=\"binary_accuracy\")\n","    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n","    axs[0].set_title('Model Accuracy')\n","    axs[0].set_ylabel('Accuracy')\n","    axs[0].set_xlabel('Epoch')\n","    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n","    axs[0].legend(['train', 'val'], loc='best')\n","    # summarize history for loss\n","    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n","    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n","    axs[1].set_title('Model Loss')\n","    axs[1].set_ylabel('Loss')\n","    axs[1].set_xlabel('Epoch')\n","    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n","    axs[1].legend(['train', 'val'], loc='best')\n","    plt.show()\n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":743},"executionInfo":{"elapsed":419,"status":"error","timestamp":1684023004502,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"},"user_tz":180},"id":"QaB6Td54816w","outputId":"fb93be42-c07e-47d7-82de-b660eaeb10f6"},"outputs":[{"ename":"KeyError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-9e98b7b828a6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-61-8f4398e9dcfa>\u001b[0m in \u001b[0;36mplot_model_history\u001b[0;34m(model_history)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#axs[0].plot(range(1,len(model_history.history['binary_accuracy'])+1),model_history.history['acc'],metrics=\"binary_accuracy\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'val_acc'"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 1500x500 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plot_model_history(model_info) #Não funciona"]}],"metadata":{"colab":{"provenance":[{"file_id":"1_wI_D48QGPWO0_vXs1xkEdqQ4vMzROj6","timestamp":1684008606151},{"file_id":"1xM9cTBBDFVvjMp6IrPfsPjRX7OXHulLn","timestamp":1683729596036}],"authorship_tag":"ABX9TyMKx/vahueQ7KoVHrxOPV9A"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}