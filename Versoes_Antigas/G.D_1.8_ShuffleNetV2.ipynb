{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzoz93Iy+9xkpwYHCnif/R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"O-AkQtuvzpte"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","import os\n","from google.colab import drive\n","\n","# Montar o Google Drive\n","drive.mount('/content/drive')\n","\n","print(os.listdir(('/content/drive/MyDrive/compara_segmentadores/data2/talho/G1020/train/images/')))"]},{"cell_type":"code","source":["!pip install torch torchvision opencv-python\n","!pip install scikit-plot\n","!pip install django-model-utils"],"metadata":{"id":"rCRvWVmqzwHs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ShuffleNetV2\n","modelo = \"ShuffleNetV2\"\n","\n","import os\n","import torch\n","import torchvision\n","from torchvision import transforms\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score\n","import seaborn as sn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","# Função para carregar as imagens e anotações\n","def load_data(root_dir):\n","    image_dir_train = os.path.join(root_dir, 'train/images')\n","    annotation_dir_train = os.path.join(root_dir, 'train/anotacoes')\n","\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),  # Redimensionar todas as imagens para o tamanho 224x224\n","        transforms.ToTensor()\n","    ])\n","\n","    train_data = torchvision.datasets.ImageFolder(\n","        root=image_dir_train,\n","        transform=transform\n","    )\n","    train_loader = torch.utils.data.DataLoader(\n","        train_data,\n","        batch_size=16,\n","        shuffle=True\n","    )\n","    return train_loader\n","\n","def test_load_data(root_dir):\n","    image_dir_test = os.path.join(root_dir, 'test/images')\n","    annotation_dir_test = os.path.join(root_dir, 'test/anotacoes')\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),  # Redimensionar todas as imagens para o tamanho 224x224\n","        transforms.ToTensor()\n","    ])\n","    test_data = torchvision.datasets.ImageFolder(\n","        root=image_dir_test,\n","        transform=transform\n","    )\n","    test_loader = torch.utils.data.DataLoader(\n","        test_data,\n","        batch_size=16,\n","        shuffle=False\n","    )\n","\n","    return test_loader\n","\n","def evaluate_model(model, data_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = correct / total\n","    return accuracy\n","\n","def validation_load_data(root_dir):  # Corrigir o nome do parâmetro para root_dir\n","    image_dir_val = os.path.join(root_dir, 'valid/images')\n","    annotation_dir_val = os.path.join(root_dir, 'valid/anotacoes')\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor()\n","    ])\n","\n","    val_data = torchvision.datasets.ImageFolder(\n","        root=image_dir_val,\n","        transform=transform\n","    )\n","    val_loader = torch.utils.data.DataLoader(\n","        val_data,\n","        batch_size=16,\n","        shuffle=False\n","    )\n","\n","    return val_loader\n","\n","def train_model(train_loader, val_loader, num_epochs,MODELO):\n","    model = torchvision.models.shufflenet_v2_x1_0(pretrained=True)\n","    num_ftrs = model.classifier[6].in_features\n","    model.classifier[6] = nn.Linear(num_ftrs, 2)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","    best_accuracy = 0.0  # Track the best test accuracy\n","    train_accuracies = []  # List to store train accuracies\n","    train_losses = []  # List to store train losses\n","\n","    best_val_accuracy = 0.0  # Track the best validation accuracy\n","    val_accuracies = []  # List to store validation accuracies\n","\n","\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","\n","        for inputs, labels in train_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        epoch_loss = running_loss / len(train_loader)\n","        train_losses.append(epoch_loss)\n","\n","        train_accuracy = evaluate_model(model, train_loader)\n","        train_accuracies.append(train_accuracy)\n","\n","        # Validation after each epoch\n","        model.eval()\n","        val_accuracy = evaluate_model(model, val_loader)\n","        val_accuracies.append(val_accuracy)\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.2%}, Validation Accuracy: {val_accuracy:.2%}, Loss: {epoch_loss:.4f}')\n","\n","        # Save the best model based on the highest validation accuracy\n","        if val_accuracy > best_accuracy:\n","            best_accuracy = val_accuracy\n","            best_model_state = model.state_dict()\n","\n","    # Save the best model checkpoint\n","    torch.save(best_model_state, MODELO)\n","\n","    return model\n","\n","\n","def test_model(model, test_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Define o dispositivo de execução\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","    y_scores = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predicted.cpu().numpy())\n","\n","            # Obter as probabilidades de saída (scores)\n","            scores = F.softmax(outputs, dim=1)\n","            y_scores.extend(scores[:, 1].cpu().numpy())\n","\n","    # Calcula a matriz de confusão\n","    cm = confusion_matrix(y_true, y_pred)\n","    tn, fp, fn, tp = cm.ravel()\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","\n","    print(\"Acurácia:\", accuracy)\n","    print(\"Precisão:\", precision)\n","    print(\"Recall:\", recall)\n","    print(\"F1-score:\", f1)\n","\n","    print(\"True Negative (TN):\", tn)\n","    print(\"False Positive (FP):\", fp)\n","    print(\"False Negative (FN):\", fn)\n","    print(\"True Positive (TP):\", tp)\n","    class_names = ['Classe 0 (Sem Glaucoma)', 'Classe 1 (Com Glaucoma)']\n","\n","    # Plot da matriz de confusão\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","    plt.title('Matriz de Confusão')\n","    plt.colorbar()\n","    tick_marks = np.arange(len(class_names))\n","    plt.xticks(tick_marks, class_names, rotation=45)\n","    plt.yticks(tick_marks, class_names)\n","    plt.xlabel('Predito')\n","    plt.ylabel('Verdadeiro')\n","    plt.show()\n","\n","    # Relatório de classificação\n","    print(\"Relatório de Classificação:\")\n","    print(classification_report(y_true, y_pred, target_names=class_names))\n","\n","    # Calcular as estatísticas ROC\n","    fpr, tpr, thresholds_roc = roc_curve(y_true, y_scores)\n","    roc_auc = roc_auc_score(y_true, y_scores)\n","\n","    # Plot do gráfico ROC\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(fpr, tpr, label='Curva ROC (AUC = {:.2f})'.format(roc_auc))\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Taxa de Falso Positivo')\n","    plt.ylabel('Taxa de Verdadeiro Positivo')\n","    plt.title('Gráfico ROC')\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","    # Calcular as estatísticas RC\n","    precision, recall, thresholds_rc = precision_recall_curve(y_true, y_scores)\n","\n","    # Plot do gráfico RC\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(recall, precision, label='Curva RC')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Gráfico RC')\n","    plt.legend(loc='lower left')\n","    plt.show()\n","\n","    # Relatório de classificação\n","    print(\"Relatório de Classificação:\")\n","    print(classification_report(y_true, y_pred, target_names=class_names))\n","\n","\n","Valid_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/ORIGA/\"\n","Teste_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/G1020/\"\n","num_epochs = 3\n","\n","Val_loader = validation_load_data(Valid_root)\n","Test_loader = test_load_data(Teste_root)\n","\n","print('\\n')\n","# Carregar os dados para G1020\n","print(\"G1020:\")\n","TrainG1020_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/G1020/\"\n","Train_loader_G1020 = load_data(TrainG1020_root)\n","G1020M = 'G1020best_model.pth'\n","MG1020M = modelo+G1020M\n","modelo_G1020 = train_model(Train_loader_G1020, Val_loader, num_epochs,MG1020M)\n","print(\"Fim do treino.\")\n","melhor_estado_modelo_G1020 = torch.load(MG1020M)\n","modelo_G1020.load_state_dict(melhor_estado_modelo_G1020)\n","test_model(modelo_G1020, Test_loader)\n","print(\"Fim do teste.\")\n","print('\\n')\n","\n","print('\\n')\n","# Carregar os dados para ORIGA\n","print(\"ORIGA:\")\n","TrainORIGA_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/ORIGA/\"\n","train_loader_ORIGA = load_data(TrainORIGA_root)\n","ORIGM = 'ORIGAbest_model.pth'\n","MORIGM = modelo+ORIGM\n","modelo_ORIGA = train_model(train_loader_ORIGA, Val_loader, num_epochs,MORIGM)\n","print(\"Fim do treino.\")\n","melhor_estado_modelo_ORIGA = torch.load(MORIGM)\n","modelo_ORIGA.load_state_dict(melhor_estado_modelo_ORIGA)\n","test_model(modelo_ORIGA, Test_loader)\n","print(\"Fim do teste.\")\n","print('\\n')\n","\n","print('\\n')\n","# Carregar os dados para REFUGE\n","print(\"REFUGE:\")\n","TrainREFUGE_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/REFUGE/\"\n","train_loader_REFUGE = load_data(TrainREFUGE_root)\n","REFUM = 'REFUGEbest_model.pth'\n","MREFUM = modelo+REFUM\n","modelo_REFUGE = train_model(train_loader_REFUGE, Val_loader, num_epochs,MREFUM)\n","print(\"Fim do treino.\")\n","melhor_estado_modelo_REFUGE = torch.load(MREFUM)\n","modelo_REFUGE.load_state_dict(melhor_estado_modelo_REFUGE)\n","test_model(modelo_REFUGE, Test_loader)\n","print(\"Fim do teste.\")\n","print('\\n')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":567},"id":"Ukxz-_vNz1bM","executionInfo":{"status":"error","timestamp":1694523613787,"user_tz":180,"elapsed":756,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"}},"outputId":"1bd728bc-15ce-421d-9266-8f72a979e958"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","G1020:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X1_0_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\" to /root/.cache/torch/hub/checkpoints/shufflenetv2_x1-5666bf0f80.pth\n","100%|██████████| 8.79M/8.79M [00:00<00:00, 80.0MB/s]\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-0056275deff3>\u001b[0m in \u001b[0;36m<cell line: 270>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0mG1020M\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'G1020best_model.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0mMG1020M\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mG1020M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m \u001b[0mmodelo_G1020\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrain_loader_G1020\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVal_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMG1020M\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fim do treino.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0mmelhor_estado_modelo_G1020\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMG1020M\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-0056275deff3>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, val_loader, num_epochs, MODELO)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMODELO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshufflenet_v2_x1_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mnum_ftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'ShuffleNetV2' object has no attribute 'classifier'"]}]}]}