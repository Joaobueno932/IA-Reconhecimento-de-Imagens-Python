{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMDoSfFgNOzdnZCkajJzgl5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","import os\n","from google.colab import drive\n","\n","# Montar o Google Drive\n","drive.mount('/content/drive')\n","\n","print(os.listdir(('/content/drive/MyDrive/compara_segmentadores/data2/talho/G1020/train/images/')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j2936hILBzIW","executionInfo":{"status":"ok","timestamp":1694281276423,"user_tz":180,"elapsed":39347,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"}},"outputId":"bd0cb404-6242-4516-eae6-06b182665ce7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","['class 0', 'class 1']\n"]}]},{"cell_type":"code","source":["!pip install torch torchvision opencv-python\n","!pip install scikit-plot\n","!pip install django-model-utils"],"metadata":{"id":"IVZVGAb-B4A9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GClgxa0-Bw2X"},"outputs":[],"source":["#Capsule Network\n","modelo = \"Capsule Network\"\n","\n","import os\n","import torch\n","import torchvision\n","from torchvision import transforms\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score\n","import seaborn as sn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import matplotlib.pyplot as plt\n","\n","\n","# Função para carregar as imagens e anotações\n","def load_data(root_dir):\n","    image_dir_train = os.path.join(root_dir, 'train/images')\n","    annotation_dir_train = os.path.join(root_dir, 'train/anotacoes')\n","\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),  # Redimensionar todas as imagens para o tamanho 224x224\n","        transforms.ToTensor()\n","    ])\n","\n","    train_data = torchvision.datasets.ImageFolder(\n","        root=image_dir_train,\n","        transform=transform\n","    )\n","    train_loader = torch.utils.data.DataLoader(\n","        train_data,\n","        batch_size=16,\n","        shuffle=True\n","    )\n","    return train_loader\n","\n","def test_load_data(root_dir):\n","    image_dir_test = os.path.join(root_dir, 'test/images')\n","    annotation_dir_test = os.path.join(root_dir, 'test/anotacoes')\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),  # Redimensionar todas as imagens para o tamanho 224x224\n","        transforms.ToTensor()\n","    ])\n","    test_data = torchvision.datasets.ImageFolder(\n","        root=image_dir_test,\n","        transform=transform\n","    )\n","    test_loader = torch.utils.data.DataLoader(\n","        test_data,\n","        batch_size=16,\n","        shuffle=False\n","    )\n","\n","    return test_loader\n","\n","def evaluate_model(model, data_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = correct / total\n","    return accuracy\n","\n","def validation_load_data(root_dir):  # Corrigir o nome do parâmetro para root_dir\n","    image_dir_val = os.path.join(root_dir, 'valid/images')\n","    annotation_dir_val = os.path.join(root_dir, 'valid/anotacoes')\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor()\n","    ])\n","\n","    val_data = torchvision.datasets.ImageFolder(\n","        root=image_dir_val,\n","        transform=transform\n","    )\n","    val_loader = torch.utils.data.DataLoader(\n","        val_data,\n","        batch_size=16,\n","        shuffle=False\n","    )\n","\n","    return val_loader\n","\n","def train_model(train_loader, val_loader, num_epochs,MODELO):\n","    model = torchvision.models.googlenet(pretrained=True)  # Usar a arquitetura GoogLeNet\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 2)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","    best_accuracy = 0.0  # Track the best test accuracy\n","    train_accuracies = []  # List to store train accuracies\n","    train_losses = []  # List to store train losses\n","\n","    best_val_accuracy = 0.0  # Track the best validation accuracy\n","    val_accuracies = []  # List to store validation accuracies\n","\n","\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","\n","        for inputs, labels in train_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        epoch_loss = running_loss / len(train_loader)\n","        train_losses.append(epoch_loss)\n","\n","        train_accuracy = evaluate_model(model, train_loader)\n","        train_accuracies.append(train_accuracy)\n","\n","        # Validation after each epoch\n","        model.eval()\n","        val_accuracy = evaluate_model(model, val_loader)\n","        val_accuracies.append(val_accuracy)\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.2%}, Validation Accuracy: {val_accuracy:.2%}, Loss: {epoch_loss:.4f}')\n","\n","        # Save the best model based on the highest validation accuracy\n","        if val_accuracy > best_accuracy:\n","            best_accuracy = val_accuracy\n","            best_model_state = model.state_dict()\n","\n","    # Save the best model checkpoint\n","    torch.save(best_model_state, MODELO)\n","\n","    return model\n","\n","\n","def test_model(model, test_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Define o dispositivo de execução\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","    y_scores = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predicted.cpu().numpy())\n","\n","            # Obter as probabilidades de saída (scores)\n","            scores = F.softmax(outputs, dim=1)\n","            y_scores.extend(scores[:, 1].cpu().numpy())\n","\n","    # Calcula a matriz de confusão\n","    cm = confusion_matrix(y_true, y_pred)\n","    tn, fp, fn, tp = cm.ravel()\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","\n","    print(\"Acurácia:\", accuracy)\n","    print(\"Precisão:\", precision)\n","    print(\"Recall:\", recall)\n","    print(\"F1-score:\", f1)\n","\n","    print(\"True Negative (TN):\", tn)\n","    print(\"False Positive (FP):\", fp)\n","    print(\"False Negative (FN):\", fn)\n","    print(\"True Positive (TP):\", tp)\n","    class_names = ['Classe 0 (Sem Glaucoma)', 'Classe 1 (Com Glaucoma)']\n","\n","    # Plot da matriz de confusão\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","    plt.title('Matriz de Confusão')\n","    plt.colorbar()\n","    tick_marks = np.arange(len(class_names))\n","    plt.xticks(tick_marks, class_names, rotation=45)\n","    plt.yticks(tick_marks, class_names)\n","    plt.xlabel('Predito')\n","    plt.ylabel('Verdadeiro')\n","    plt.show()\n","\n","    # Relatório de classificação\n","    print(\"Relatório de Classificação:\")\n","    print(classification_report(y_true, y_pred, target_names=class_names))\n","\n","    # Calcular as estatísticas ROC\n","    fpr, tpr, thresholds_roc = roc_curve(y_true, y_scores)\n","    roc_auc = roc_auc_score(y_true, y_scores)\n","\n","    # Plot do gráfico ROC\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(fpr, tpr, label='Curva ROC (AUC = {:.2f})'.format(roc_auc))\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Taxa de Falso Positivo')\n","    plt.ylabel('Taxa de Verdadeiro Positivo')\n","    plt.title('Gráfico ROC')\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","    # Calcular as estatísticas RC\n","    precision, recall, thresholds_rc = precision_recall_curve(y_true, y_scores)\n","\n","    # Plot do gráfico RC\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(recall, precision, label='Curva RC')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Gráfico RC')\n","    plt.legend(loc='lower left')\n","    plt.show()\n","\n","    # Relatório de classificação\n","    print(\"Relatório de Classificação:\")\n","    print(classification_report(y_true, y_pred, target_names=class_names))\n","\n","\n","Valid_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/ORIGA/\"\n","Teste_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/G1020/\"\n","num_epochs = 3\n","\n","Val_loader = validation_load_data(Valid_root)\n","Test_loader = test_load_data(Teste_root)\n","\n","print('\\n')\n","# Carregar os dados para G1020\n","print(\"G1020:\")\n","TrainG1020_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/G1020/\"\n","Train_loader_G1020 = load_data(TrainG1020_root)\n","G1020M = 'G1020best_model.pth'\n","MG1020M = modelo+G1020M\n","modelo_G1020 = train_model(Train_loader_G1020, Val_loader, num_epochs,MG1020M)\n","print(\"Fim do treino.\")\n","melhor_estado_modelo_G1020 = torch.load(MG1020M)\n","modelo_G1020.load_state_dict(melhor_estado_modelo_G1020)\n","test_model(modelo_G1020, Test_loader)\n","print(\"Fim do teste.\")\n","print('\\n')\n","\n","print('\\n')\n","# Carregar os dados para ORIGA\n","print(\"ORIGA:\")\n","TrainORIGA_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/ORIGA/\"\n","train_loader_ORIGA = load_data(TrainORIGA_root)\n","ORIGM = 'ORIGAbest_model.pth'\n","MORIGM = modelo+ORIGM\n","modelo_ORIGA = train_model(train_loader_ORIGA, Val_loader, num_epochs,MORIGM)\n","print(\"Fim do treino.\")\n","melhor_estado_modelo_ORIGA = torch.load(MORIGM)\n","modelo_ORIGA.load_state_dict(melhor_estado_modelo_ORIGA)\n","test_model(modelo_ORIGA, Test_loader)\n","print(\"Fim do teste.\")\n","print('\\n')\n","\n","print('\\n')\n","# Carregar os dados para REFUGE\n","print(\"REFUGE:\")\n","TrainREFUGE_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/REFUGE/\"\n","train_loader_REFUGE = load_data(TrainREFUGE_root)\n","REFUM = 'REFUGEbest_model.pth'\n","MREFUM = modelo+REFUM\n","modelo_REFUGE = train_model(train_loader_REFUGE, Val_loader, num_epochs,MREFUM)\n","print(\"Fim do treino.\")\n","melhor_estado_modelo_REFUGE = torch.load(MREFUM)\n","modelo_REFUGE.load_state_dict(melhor_estado_modelo_REFUGE)\n","test_model(modelo_REFUGE, Test_loader)\n","print(\"Fim do teste.\")\n","print('\\n')\n"]}]}