{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29521,"status":"ok","timestamp":1694554736509,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"},"user_tz":240},"id":"3hxzpTmKXYFr","outputId":"dce98e8a-9ea7-49a3-e9d1-982be102f4c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","['class 0', 'class 1']\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","from torch.utils.data.dataset import Dataset\n","import os\n","from google.colab import drive\n","\n","# Montar o Google Drive\n","drive.mount('/content/drive')\n","\n","print(os.listdir(('/content/drive/MyDrive/compara_segmentadores/data2/talho/G1020/train/images/')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qteedQJXb2S"},"outputs":[],"source":["!pip install torch torchvision opencv-python\n","!pip install scikit-plot\n","!pip install django-model-utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DMDxT4z1ZE4S"},"outputs":[],"source":["pip install timm"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"elapsed":3075,"status":"error","timestamp":1694554751977,"user":{"displayName":"Kevin Nicolas Costantino","userId":"03967773680110882059"},"user_tz":240},"id":"-sn1udZpXtQS","outputId":"7d0b080c-81c3-4a96-e709-7174b06515ac"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-3-efcb49790efc\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 269\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 269\u001b[0;31m \u001b[0mVal_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mValid_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0mTest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTeste_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-3-efcb49790efc\u003e\u001b[0m in \u001b[0;36mvalidation_load_data\u001b[0;34m(root_dir)\u001b[0m\n\u001b[1;32m     87\u001b[0m     ])\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 89\u001b[0;31m     val_data = torchvision.datasets.ImageFolder(\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_dir_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"]}],"source":["#SENet\n","modelo = \"SENet\"\n","\n","import os\n","import torch\n","from torch import nn, optim\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score\n","import seaborn as sn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import timm\n","\n","# Função para carregar as imagens e anotações\n","def load_data(root_dir):\n","    image_dir_train = os.path.join(root_dir, 'train/images')\n","    annotation_dir_train = os.path.join(root_dir, 'train/anotacoes')\n","\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),  # Redimensionar todas as imagens para o tamanho 224x224\n","        transforms.ToTensor()\n","    ])\n","\n","    train_data = torchvision.datasets.ImageFolder(\n","        root=image_dir_train,\n","        transform=transform\n","    )\n","    train_loader = torch.utils.data.DataLoader(\n","        train_data,\n","        batch_size=16,\n","        shuffle=True\n","    )\n","    return train_loader\n","\n","def test_load_data(root_dir):\n","    image_dir_test = os.path.join(root_dir, 'test/images')\n","    annotation_dir_test = os.path.join(root_dir, 'test/anotacoes')\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),  # Redimensionar todas as imagens para o tamanho 224x224\n","        transforms.ToTensor()\n","    ])\n","    test_data = torchvision.datasets.ImageFolder(\n","        root=image_dir_test,\n","        transform=transform\n","    )\n","    test_loader = torch.utils.data.DataLoader(\n","        test_data,\n","        batch_size=16,\n","        shuffle=False\n","    )\n","\n","    return test_loader\n","\n","def evaluate_model(model, data_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = correct / total\n","    return accuracy\n","\n","def validation_load_data(root_dir):  # Corrigir o nome do parâmetro para root_dir\n","    image_dir_val = os.path.join(root_dir, 'valid/images')\n","    annotation_dir_val = os.path.join(root_dir, 'valid/anotacoes')\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor()\n","    ])\n","\n","    val_data = torchvision.datasets.ImageFolder(\n","        root=image_dir_val,\n","        transform=transform\n","    )\n","    val_loader = torch.utils.data.DataLoader(\n","        val_data,\n","        batch_size=16,\n","        shuffle=False\n","    )\n","\n","    return val_loader\n","\n","def train_model(train_loader, val_loader, num_epochs,MODELO):\n","    model = timm.create_model('seresnext26d_32x4d', pretrained=True)  # Use a arquitetura SENet, por exemplo, 'senet154'\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 2)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","    best_accuracy = 0.0  # Track the best test accuracy\n","    train_accuracies = []  # List to store train accuracies\n","    train_losses = []  # List to store train losses\n","\n","    best_val_accuracy = 0.0  # Track the best validation accuracy\n","    val_accuracies = []  # List to store validation accuracies\n","\n","\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","\n","        for inputs, labels in train_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        epoch_loss = running_loss / len(train_loader)\n","        train_losses.append(epoch_loss)\n","\n","        train_accuracy = evaluate_model(model, train_loader)\n","        train_accuracies.append(train_accuracy)\n","\n","        # Validation after each epoch\n","        model.eval()\n","        val_accuracy = evaluate_model(model, val_loader)\n","        val_accuracies.append(val_accuracy)\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.2%}, Validation Accuracy: {val_accuracy:.2%}, Loss: {epoch_loss:.4f}')\n","\n","        #aux = round(val_accuracy,2)\n","        # Save the best model based on the highest validation accuracy\n","        #if aux != 0.83 or epoch == num_epochs-1:\n","        #       if val_accuracy \u003e best_accuracy:\n","        #         best_accuracy = val_accuracy\n","        #         print(\"best_accuracy:\", best_accuracy,)\n","        #         print(\"val_accuracy:\", val_accuracy)\n","        #         print(\"aux:\", aux)\n","        #else:\n","        #       print(\"best_accuracy:\", best_accuracy,)\n","\n","        # Save the best model based on the highest validation accuracy\n","        if val_accuracy \u003e best_accuracy:\n","            best_accuracy = val_accuracy\n","            best_model_state = model.state_dict()\n","\n","    # Save the best model checkpoint\n","    torch.save(best_model_state, MODELO)\n","\n","    return model\n","\n","\n","def test_model(model, test_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Define o dispositivo de execução\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","    y_scores = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predicted.cpu().numpy())\n","\n","            # Obter as probabilidades de saída (scores)\n","            scores = F.softmax(outputs, dim=1)\n","            y_scores.extend(scores[:, 1].cpu().numpy())\n","\n","    # Calcula a matriz de confusão\n","    cm = confusion_matrix(y_true, y_pred)\n","    tn, fp, fn, tp = cm.ravel()\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","\n","    print(\"Acurácia:\", accuracy)\n","    print(\"Precisão:\", precision)\n","    print(\"Recall:\", recall)\n","    print(\"F1-score:\", f1)\n","\n","    print(\"True Negative (TN):\", tn)\n","    print(\"False Positive (FP):\", fp)\n","    print(\"False Negative (FN):\", fn)\n","    print(\"True Positive (TP):\", tp)\n","    class_names = ['Classe 0 (Sem Glaucoma)', 'Classe 1 (Com Glaucoma)']\n","\n","    # Plot da matriz de confusão\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","    plt.title('Matriz de Confusão')\n","    plt.colorbar()\n","    tick_marks = np.arange(len(class_names))\n","    plt.xticks(tick_marks, class_names, rotation=45)\n","    plt.yticks(tick_marks, class_names)\n","    plt.xlabel('Predito')\n","    plt.ylabel('Verdadeiro')\n","    plt.show()\n","\n","    # Relatório de classificação\n","    print(\"Relatório de Classificação:\")\n","    print(classification_report(y_true, y_pred, target_names=class_names))\n","\n","    # Calcular as estatísticas ROC\n","    fpr, tpr, thresholds_roc = roc_curve(y_true, y_scores)\n","    roc_auc = roc_auc_score(y_true, y_scores)\n","\n","    # Plot do gráfico ROC\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(fpr, tpr, label='Curva ROC (AUC = {:.2f})'.format(roc_auc))\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Taxa de Falso Positivo')\n","    plt.ylabel('Taxa de Verdadeiro Positivo')\n","    plt.title('Gráfico ROC')\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","    # Calcular as estatísticas RC\n","    precision, recall, thresholds_rc = precision_recall_curve(y_true, y_scores)\n","\n","    # Plot do gráfico RC\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(recall, precision, label='Curva RC')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Gráfico RC')\n","    plt.legend(loc='lower left')\n","    plt.show()\n","\n","    # Relatório de classificação\n","    print(\"Relatório de Classificação:\")\n","    print(classification_report(y_true, y_pred, target_names=class_names))\n","\n","\n","Valid_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/ORIGA/\"\n","Teste_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/G1020/\"\n","num_epochs = 3\n","\n","Val_loader = validation_load_data(Valid_root)\n","Test_loader = test_load_data(Teste_root)\n","\n","print('\\n')\n","# Carregar os dados para G1020\n","print(\"G1020:\")\n","TrainG1020_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/G1020/\"\n","Train_loader_G1020 = load_data(TrainG1020_root)\n","G1020M = 'G1020best_model.pth'\n","MG1020M = modelo+G1020M\n","modelo_G1020 = train_model(Train_loader_G1020, Val_loader, num_epochs,MG1020M)\n","print(\"Fim do treino.\")\n","melhor_estado_modelo_G1020 = torch.load(MG1020M)\n","modelo_G1020.load_state_dict(melhor_estado_modelo_G1020)\n","test_model(modelo_G1020, Test_loader)\n","print(\"Fim do teste.\")\n","print('\\n')\n","\n","print('\\n')\n","# Carregar os dados para ORIGA\n","print(\"ORIGA:\")\n","TrainORIGA_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/ORIGA/\"\n","train_loader_ORIGA = load_data(TrainORIGA_root)\n","ORIGM = 'ORIGAbest_model.pth'\n","MORIGM = modelo+ORIGM\n","modelo_ORIGA = train_model(train_loader_ORIGA, Val_loader, num_epochs,MORIGM)\n","print(\"Fim do treino.\")\n","melhor_estado_modelo_ORIGA = torch.load(MORIGM)\n","modelo_ORIGA.load_state_dict(melhor_estado_modelo_ORIGA)\n","test_model(modelo_ORIGA, Test_loader)\n","print(\"Fim do teste.\")\n","print('\\n')\n","\n","print('\\n')\n","# Carregar os dados para REFUGE\n","print(\"REFUGE:\")\n","TrainREFUGE_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/REFUGE/\"\n","train_loader_REFUGE = load_data(TrainREFUGE_root)\n","REFUM = 'REFUGEbest_model.pth'\n","MREFUM = modelo+REFUM\n","modelo_REFUGE = train_model(train_loader_REFUGE, Val_loader, num_epochs,MREFUM)\n","print(\"Fim do treino.\")\n","melhor_estado_modelo_REFUGE = torch.load(MREFUM)\n","modelo_REFUGE.load_state_dict(melhor_estado_modelo_REFUGE)\n","test_model(modelo_REFUGE, Test_loader)\n","print(\"Fim do teste.\")\n","print('\\n')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2BNtJNYUU83B"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","G1020:\n","Epoch [1/3], Train Accuracy: 71.37%, Validation Accuracy: 83.33%, Loss: 0.6343\n","Epoch [2/3], Train Accuracy: 71.37%, Validation Accuracy: 82.22%, Loss: 0.6177\n","Epoch [3/3], Train Accuracy: 67.51%, Validation Accuracy: 71.67%, Loss: 0.6153\n","Fim do treino.\n"]},{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-9-bb7807c5d050\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 285\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0mmelhor_estado_modelo_G1020\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMG1020M\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0mmodelo_G1020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelhor_estado_modelo_G1020\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 285\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelo_G1020\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fim do teste.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-9-bb7807c5d050\u003e\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# Obter as probabilidades de saída (scores)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 194\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0my_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"]}],"source":["#SENet\n","modelo = \"SENet\"\n","\n","import os\n","import torch\n","import torchvision\n","from torch import nn, optim\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score\n","import seaborn as sn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import timm\n","\n","\n","# Função para carregar as imagens e anotações\n","def load_data(root_dir):\n","    image_dir_train = os.path.join(root_dir, 'train/images')\n","    annotation_dir_train = os.path.join(root_dir, 'train/anotacoes')\n","\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),  # Redimensionar todas as imagens para o tamanho 224x224\n","        transforms.ToTensor()\n","    ])\n","\n","    train_data = torchvision.datasets.ImageFolder(\n","        root=image_dir_train,\n","        transform=transform\n","    )\n","    train_loader = torch.utils.data.DataLoader(\n","        train_data,\n","        batch_size=16,\n","        shuffle=True\n","    )\n","    return train_loader\n","\n","def test_load_data(root_dir):\n","    image_dir_test = os.path.join(root_dir, 'test/images')\n","    annotation_dir_test = os.path.join(root_dir, 'test/anotacoes')\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),  # Redimensionar todas as imagens para o tamanho 224x224\n","        transforms.ToTensor()\n","    ])\n","    test_data = torchvision.datasets.ImageFolder(\n","        root=image_dir_test,\n","        transform=transform\n","    )\n","    test_loader = torch.utils.data.DataLoader(\n","        test_data,\n","        batch_size=16,\n","        shuffle=False\n","    )\n","\n","    return test_loader\n","\n","def evaluate_model(model, data_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = correct / total\n","    return accuracy\n","\n","def validation_load_data(root_dir):  # Corrigir o nome do parâmetro para root_dir\n","    image_dir_val = os.path.join(root_dir, 'valid/images')\n","    annotation_dir_val = os.path.join(root_dir, 'valid/anotacoes')\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor()\n","    ])\n","\n","    val_data = torchvision.datasets.ImageFolder(\n","        root=image_dir_val,\n","        transform=transform\n","    )\n","    val_loader = torch.utils.data.DataLoader(\n","        val_data,\n","        batch_size=16,\n","        shuffle=False\n","    )\n","\n","    return val_loader\n","\n","def train_model(train_loader, val_loader, num_epochs,MODELO):\n","    model = timm.create_model('seresnet101')  # Use a arquitetura SENet, por exemplo, 'senet154'\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 2)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","    best_accuracy = 0.0  # Track the best test accuracy\n","    train_accuracies = []  # List to store train accuracies\n","    train_losses = []  # List to store train losses\n","\n","    best_val_accuracy = 0.0  # Track the best validation accuracy\n","    val_accuracies = []  # List to store validation accuracies\n","\n","\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","\n","        for inputs, labels in train_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        epoch_loss = running_loss / len(train_loader)\n","        train_losses.append(epoch_loss)\n","\n","        train_accuracy = evaluate_model(model, train_loader)\n","        train_accuracies.append(train_accuracy)\n","\n","        # Validation after each epoch\n","        model.eval()\n","        val_accuracy = evaluate_model(model, val_loader)\n","        val_accuracies.append(val_accuracy)\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.2%}, Validation Accuracy: {val_accuracy:.2%}, Loss: {epoch_loss:.4f}')\n","\n","        #aux = round(val_accuracy,2)\n","        # Save the best model based on the highest validation accuracy\n","        #if aux != 0.83 or epoch == num_epochs-1:\n","        #       if val_accuracy \u003e best_accuracy:\n","        #         best_accuracy = val_accuracy\n","        #         print(\"best_accuracy:\", best_accuracy,)\n","        #         print(\"val_accuracy:\", val_accuracy)\n","        #         print(\"aux:\", aux)\n","        #else:\n","        #       print(\"best_accuracy:\", best_accuracy,)\n","\n","        # Save the best model based on the highest validation accuracy\n","        if val_accuracy \u003e best_accuracy:\n","            best_accuracy = val_accuracy\n","            best_model_state = model.state_dict()\n","\n","    # Save the best model checkpoint\n","    torch.save(best_model_state, MODELO)\n","\n","    return model\n","\n","\n","def test_model(model, test_loader):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Define o dispositivo de execução\n","    model.eval()\n","    y_true = []\n","    y_pred = []\n","    y_scores = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predicted.cpu().numpy())\n","\n","            # Obter as probabilidades de saída (scores)\n","            scores = F.softmax(outputs, dim=1)\n","            y_scores.extend(scores[:, 1].cpu().numpy())\n","\n","    # Calcula a matriz de confusão\n","    cm = confusion_matrix(y_true, y_pred)\n","    tn, fp, fn, tp = cm.ravel()\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","\n","    print(\"Acurácia:\", accuracy)\n","    print(\"Precisão:\", precision)\n","    print(\"Recall:\", recall)\n","    print(\"F1-score:\", f1)\n","\n","    print(\"True Negative (TN):\", tn)\n","    print(\"False Positive (FP):\", fp)\n","    print(\"False Negative (FN):\", fn)\n","    print(\"True Positive (TP):\", tp)\n","    class_names = ['Classe 0 (Sem Glaucoma)', 'Classe 1 (Com Glaucoma)']\n","\n","    # Plot da matriz de confusão\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","    plt.title('Matriz de Confusão')\n","    plt.colorbar()\n","    tick_marks = np.arange(len(class_names))\n","    plt.xticks(tick_marks, class_names, rotation=45)\n","    plt.yticks(tick_marks, class_names)\n","    plt.xlabel('Predito')\n","    plt.ylabel('Verdadeiro')\n","    plt.show()\n","\n","    # Relatório de classificação\n","    print(\"Relatório de Classificação:\")\n","    print(classification_report(y_true, y_pred, target_names=class_names))\n","\n","    # Calcular as estatísticas ROC\n","    fpr, tpr, thresholds_roc = roc_curve(y_true, y_scores)\n","    roc_auc = roc_auc_score(y_true, y_scores)\n","\n","    # Plot do gráfico ROC\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(fpr, tpr, label='Curva ROC (AUC = {:.2f})'.format(roc_auc))\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Taxa de Falso Positivo')\n","    plt.ylabel('Taxa de Verdadeiro Positivo')\n","    plt.title('Gráfico ROC')\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","    # Calcular as estatísticas RC\n","    precision, recall, thresholds_rc = precision_recall_curve(y_true, y_scores)\n","\n","    # Plot do gráfico RC\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(recall, precision, label='Curva RC')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('Recall')\n","    plt.ylabel('Precision')\n","    plt.title('Gráfico RC')\n","    plt.legend(loc='lower left')\n","    plt.show()\n","\n","    # Relatório de classificação\n","    print(\"Relatório de Classificação:\")\n","    print(classification_report(y_true, y_pred, target_names=class_names))\n","\n","\n","Valid_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/ORIGA/\"\n","Teste_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/G1020/\"\n","num_epochs = 3\n","\n","Val_loader = validation_load_data(Valid_root)\n","Test_loader = test_load_data(Teste_root)\n","\n","print('\\n')\n","# Carregar os dados para G1020\n","print(\"G1020:\")\n","TrainG1020_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/G1020/\"\n","Train_loader_G1020 = load_data(TrainG1020_root)\n","G1020M = 'G1020best_model.pth'\n","MG1020M = modelo+G1020M\n","modelo_G1020 = train_model(Train_loader_G1020, Val_loader, num_epochs,MG1020M)\n","print(\"Fim do treino.\")\n","melhor_estado_modelo_G1020 = torch.load(MG1020M)\n","modelo_G1020.load_state_dict(melhor_estado_modelo_G1020)\n","test_model(modelo_G1020, Test_loader)\n","print(\"Fim do teste.\")\n","print('\\n')\n","\n","print('\\n')\n","# Carregar os dados para ORIGA\n","print(\"ORIGA:\")\n","TrainORIGA_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/ORIGA/\"\n","train_loader_ORIGA = load_data(TrainORIGA_root)\n","ORIGM = 'ORIGAbest_model.pth'\n","MORIGM = modelo+ORIGM\n","modelo_ORIGA = train_model(train_loader_ORIGA, Val_loader, num_epochs,MORIGM)\n","print(\"Fim do treino.\")\n","melhor_estado_modelo_ORIGA = torch.load(MORIGM)\n","modelo_ORIGA.load_state_dict(melhor_estado_modelo_ORIGA)\n","test_model(modelo_ORIGA, Test_loader)\n","print(\"Fim do teste.\")\n","print('\\n')\n","\n","print('\\n')\n","# Carregar os dados para REFUGE\n","print(\"REFUGE:\")\n","TrainREFUGE_root = \"/content/drive/MyDrive/compara_segmentadores/data2/talho/REFUGE/\"\n","train_loader_REFUGE = load_data(TrainREFUGE_root)\n","REFUM = 'REFUGEbest_model.pth'\n","MREFUM = modelo+REFUM\n","modelo_REFUGE = train_model(train_loader_REFUGE, Val_loader, num_epochs,MREFUM)\n","print(\"Fim do treino.\")\n","melhor_estado_modelo_REFUGE = torch.load(MREFUM)\n","modelo_REFUGE.load_state_dict(melhor_estado_modelo_REFUGE)\n","test_model(modelo_REFUGE, Test_loader)\n","print(\"Fim do teste.\")\n","print('\\n')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPq+I23Y7NsZm4gxNlG3I56","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}